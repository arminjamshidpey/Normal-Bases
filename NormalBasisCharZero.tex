\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{tikz}
\usepackage{mathdots}

\newcommand{\osum}[2]{\alpha_{#1,#2}}
\newcommand{\osumcost}{O(n^{3/4 \omega(4/3)})}
\newcommand{\osumcosttilde}{\tilde{O}(n^{3/4 \omega(4/3)})}

{
      \theoremstyle{acmplain}
      \newtheorem{assumption}{Assumption}
  }


% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[WOODSTOCK'97]{ACM Woodstock conference}{July 1997}{El
  Paso, Texas USA} 
\acmYear{1997}
\copyrightyear{2016}


\acmArticle{4}
\acmPrice{15.00}

% These commands are optional
%\acmBooktitle{Transactions of the ACM Woodstock conference}
%\editor{Jennifer B. Sartor}
%\editor{Theo D'Hondt}
%\editor{Wolfgang De Meuter}


\begin{document}
\title{Randomized Algorithms for Normal Bases}
%\titlenote{Produces the permission block, and
%  copyright information}
%\subtitle{Extended Abstract}
%\subtitlenote{The full version of the author's guide is available as
%  \texttt{acmart.pdf} document}


\author{Mark Giesbrecht
}
\affiliation{%
  \institution{Cheriton School of Computer Science
University of Waterloo}
}
\email{mwg@uwaterloo.ca}

\author{Armin Jamshidpey}
\affiliation{%
  \institution{Cheriton School of Computer Science
University of Waterloo}
}
\email{armin.jamshidpey@uwaterloo.ca}

\author{\'Eric Schost}
\affiliation{%
  \institution{Cheriton School of Computer Science
University of Waterloo}
}
\email{eschost@uwaterloo.ca}


% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{M. Giesbrecht et al.}




\begin{abstract}
It is known that for any finite Galois extension $K/F$ there exists an element $\alpha$, such that its Galois 
Conjugates form a $F$-basis of $K$. In this paper we introduce a randomized algorithm for finding such an 
element in a given finite Galois extension.   
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}
%
%
%\keywords{ACM proceedings, \LaTeX, text tagging}


\maketitle

\section{Introduction}

For a finite Galois extension $K/F$ with $G = \mathrm{Gal}(K/F)$, an element $\alpha \in K$
is called normal if the set of Galois conjugates of $\alpha$ forms a basis for $K$ as a
 vector space over $F$. The existence of normal element for any finite Galois extension is 
 known for a long time.

There are several algorithms for finding a normal element in zero characteristic and finite fields. Due to the applications of
finite fields, normal element in this case is more popular. H. W. Lenstra in \cite{LenstraNormal} introduced an deterministic 
algorithm which uses $O(n^{O(1)})$ operations over the smaller field where $n$ is the degree of the extension. To the best of
our knowledge, the algorithm introduced by Augot and Camion (cite) is the most efficient deterministic one with $O(n^3+n^2\log q)$
where $q$ is size of the base field. Randomized algorithems for finite fileds are introduced in \cite{Giesbrecht} with cost
$O(n^2+n\log q)$ and \cite{Kaltoefen} with cost $O(n^{1.8})$. In characteristic zero, A. Poli gave an algorithm for abelian extensions in \cite{Poli} with $O(n^{O(1)})$ and Schlickewei and Stepanov introduced an algorithm in the cyclic case with
$O(n^{O(1)})$. Girstmair has an algorithm which uses $O(n^4)$ operations over the base field to construct a normal element for 
a general finite Galois extension in characteristic zero. In this work we will introduce a randomized algorithm for finding a
normal element in case of abelian and metacyclic extensions which is subquadratic in the degree of the extension.

 
One of the well-known proofs suggests a randomized algorithm for finding such an element. 
Assume $K/F$ is a finite Galois extension with Galois group $G = \lbrace g_1 , \ldots ,
 g_n \rbrace$. If $x \in K$ is a normal element, 
 \begin{equation}\label{eq:fstrow}
 \sum_{j=1}^n 
 c_j g_j(x)=0, \,\,\, c_j \in F 
 \end{equation} 
 implies $(c_1, \ldots ,c_n) = 0$. For each $i \in \lbrace 1, \ldots , n\rbrace$, applying $g_i$ to equation (\ref{eq:fstrow}) yields
\begin{equation} \label{eq:otherrow}
 \sum_{j=1}^n 
 c_j g_i g_j(x)=0.
 \end{equation}
 Using equations \ref{eq:fstrow} and \ref{eq:otherrow} one can form a linear system with 
 matrix 
 $$ M_G(x) =
\begin{bmatrix}
g_1 g_1(x) & g_1 g_2(x) & \cdots & g_1 g_n(x) \\
g_2 g_1(x) & g_2 g_2(x) & \cdots & g_2 g_n(x) \\
\vdots		& \vdots	& \vdots & \vdots \\
g_n g_1(x) & g_n g_2(x) & \cdots & g_n g_n(x) \\
\end{bmatrix} 
 $$
 such that $M_G(x)$ is invertible. It is known that there exists $\alpha \in K$ with 
 $\det(M_G(\alpha))\neq 0$  (see \cite[Theorem 6.13.1]{Lang}).
 
 
 Based on above discussion one can see there exists a randomized algorithm for finding a
 normal element.\\
 \\
 \textbf{Algorithm 1.} \label{Alg:Naive}
 The algorithm takes a finite Galois extension $K/F$ with 
 $G =  \mathrm{Gal}(K/F) = \lbrace g_1, g_2, \ldots , g_n \rbrace$ and returns a normal
 element $\alpha \in K$.
 \begin{description}
 \item \textbf{step 1.} choose a random element $\alpha$ in $K$.
 \item \textbf{step 2.} write the matrix $M_G(\alpha)$.
 \item \textbf{step 3.} if $ M_G(\alpha)$ is invertible\\
% \hspace{2cm} if $r = n$ \\
 \hspace{10cm} return $\alpha$\\
 \hspace{2cm} else \\
 \hspace{5cm} go to step 1.\\  
 \end{description}
 
 Clearly the main concerns are step 2 and step 3. In \cite{Giesbrecht} instead of writing the matrix, the invertibility
 test is done by means of finding the gcd of an associated polynomial to $M_G(\alpha)$ and $x^n-1$, since in the cyclic
 case $M_G(\alpha)$ is circulant.
 
 In order to give an explicit randomized algorithm based on the Algorithm (\ref{Alg:Naive}), we need to know 
 the probability of success. Since we are working over characteristic zero, we are able to consider a finite subset
 of $K \cong F^n$ such that the probability of failure is $\dfrac{1}{n}$, using 
 Schwartz-Zippel lemma.
 \\
 \\
 If $\lbrace a_1, \ldots , a_n \rbrace$ is an $F$-basis for $K$, then in equations
   \ref{eq:fstrow} and \ref{eq:otherrow}, $x$ can be written as $\sum_{i = 1}^nx_i
    a_i$. Now we can rewrite 
    $$
M_G(x) = M_G(x_1,\ldots,x_n) =  $$
$$
\begin{bmatrix}
\sum_{i = 1}^n g_1 g_1(a_i)x_i & \sum_{i = 1}^n g_1 g_2(a_i)x_i & \cdots & 
\sum_{i = 1}^n g_1 g_n(a_i)x_i \\
\sum_{i = 1}^n g_2 g_1(a_i)x_i & \sum_{i = 1}^n g_2 g_2(a_i)x_i & \cdots & 
\sum_{i = 1}^n g_2 g_n(a_i)x_i \\
\vdots		& \vdots	& \vdots & \vdots \\
\sum_{i = 1}^n g_n g_1(a_i)x_i & \sum_{i = 1}^n g_n g_2(a_i)x_i & \cdots & 
\sum_{i = 1}^n g_n g_n(a_i)x_i \\
\end{bmatrix}    
    $$ 
 The following theorem enables us to talk about probability of success (or failure).
 \begin{theorem}\cite[Proposition 98]{Zippel} \label{Thm:Zippel}
Let $P \in A[X_1, \ldots, X_n]$ be a polynomial with total degree $D$ over an integral domain $A$. Let $S$ be a subset of $A$ of cardinality $B$. Then $$Pr(P(x_1, \ldots , x_n)=0:x_i \in S) \leq \dfrac{D}{B}.$$
\end{theorem}

Now $\det(M_G(x)) \in K[x_1, \ldots , x_n]$ is a polynomial of total degree $n$ and $K$ is a field. If $char(K) =0$, then by considering $S \subset F \subset K$ where $|S| = n^2$ and applying the above proposition we get $$Pr(\det(M_G(r_1,\ldots , r_n)) = 0 : r_i \in S)\leq \dfrac{n}{n^2}= \dfrac{1}{n}.$$

%For Steps 2 and 3 various algorithms are introduced by other authors in positive
% characteristic. The references will be given in the next section.
 
 A close look at $M_G(x)$ tells us it is exactly the matrix of (left) multiplication by $$\alpha_{G,K} = \sum_{g \in G} g(\alpha)g \in K[G].$$  This gives an idea to modify Algorithm \ref{Alg:Naive}. Instead of writing $M_G(x)$ and test its invertiblity, 
 we can write $u_\alpha$ and test if it is invertible in $K[G]$. Note that if $G$ is cyclic then $K[G] \cong K[x]/(x^n-1)$,
 $\osum{G}{K}$ is the associated polynomial to $M_G(\alpha)$ and $M_G(\alpha)$ is invertible if and only if 
 $\gcd (\osum{G}{K},x^n-1) = 1 $.
 
\begin{assumption}
$K/F$ is a finite Galois extension given by $ F[x]/f$ for an irreducible polynomial $f\in F[x]$ of degree $n$, with
 $G = \mathrm{Gal}(K/F)$. Moreover $\alpha$ is an element of $K$ and the action of $g \in G$ on $K$ is given by a
 polynomial in $F[x]$ of degree less than $n$. For simplicity we use the same notation $g$ for the mentioned 
 polynomial.
\end{assumption}

\begin{lemma}\label{Lem:Proj}
Assume $\alpha \in K$. $M_G(\alpha) \in M_{n \times n}(K)$ 
is invertible if and only if $$l(M_G(\alpha)) =  [l(g_ig_j(\alpha))]_{ij}  \in M_{n \times n}(F)$$ is invertible,
 where $l$ is a generic projection of $K$ to $F$.
\end{lemma}

\begin{proof}
$(\Rightarrow)$ Since $K = F(\theta)$, for a fixed $\alpha$, any entry of $M_G(\alpha)$ can be written as 
\begin{equation}\label{Eq:PrimElm}
\sum_{k= 0}^{n-1} a_{ijk}\theta^k
\end{equation}
 and the corresponding entry in $l(M_G(\alpha))$ (for a random projection $l$)
 can be written $\sum_{k= 0}^{n-1} a_{ijk}l_k$ with $l_k\in F$. If we replace this specific choice of $l_k$'s by 
 indeterminates $x_k$'s, we can see $\det(X(M_G(\alpha))$ is a polynomial in $F[x_1, \ldots, x_n].$ Let 
 $$P(x_1, \ldots, x_n) = \det(X(M_G(\alpha)).$$ 
 Considering $P \in K[x_1, \ldots , x_n]$, one can verify that 
 \begin{equation}\label{Eq:Det}
 det(M_G(\alpha))= P(1, \theta, \ldots, \theta^{n-1}) \neq 0
 \end{equation}
 since $M_G(\alpha)$ is invertible. Equation \ref{Eq:Det} implies that $P(x_1, \ldots, x_n)$ is not identically zero over $F$. Hence applying Theorem \ref{Thm:Zippel} with appropriate choice of parameters, we can see 
 the projection of $M_G(\alpha)$ is invertible for a generic choice of projection. 
 
 $(\Leftarrow)$  Note that elements of $G$ can act on 
 rows of $M_G(\alpha)$ entrywise and the action permutes the rows of $M_G(\alpha)$. Assume $\varphi : G \longrightarrow \mathfrak{S}_n$ is the group homomorphism 
 such that $g(M_i) = M_{\varphi(g)(i)}$ where $M_i$ is the $i$-th row of $M_G(\alpha)$.
 
 Assume $M_G(\alpha)$ is not invertible. Following the proof of \cite[Lemma 4]{Armin}, we show that there exists a non-zero $\textbf{u} \in F^n$ in the kernel of $M_G(\alpha)$. 
 
 Since $M_G(\alpha)$ is singular, there exists a non-zero $\textbf{v} \in K^n$  such that $M_G(\alpha)\textbf{v} = 0$ and $\textbf{v}$ has the minimum number of non-zero entries. Let $i \in  \lbrace 1, \ldots , n \rbrace$ such that $v_i \neq 0$. Define $\textbf{u} = \dfrac{1}{v_i}\textbf{v}$. It is clear  that $M_G(\alpha)\textbf{u} = 0$ which means $M_j \textbf{u} = 0 $ for $j \in \lbrace 1, \ldots, n \rbrace$. For $g \in G$
 \begin{equation}
  g(M_j \textbf{u}) = M_{\varphi(g)(j)} \textbf{u}= 0
 \end{equation}
 Since the above equation holds for any $j$ we conclude that $$M_G(\alpha)g(\textbf{u})= 0$$ hence
 $g(\textbf{u})-\textbf{u}$ is in the kernel of $M_G(\alpha)$. On the other hand since the $i$-th entry 
 of $\textbf{u}$ is one, the $i$-th entry of $g(\textbf{u}) -\textbf{u}$ is zero. Thus the minimality assumption
 on $\textbf{v}$ shows that $g(\textbf{u}) -\textbf{u} = 0$ and equivalently $g(\textbf{u})=\textbf{u}$. This 
 means $\textbf{u} \in F^n$.
 
 
 Now we show that $l(M_G(\alpha))$ is not invertible for all
 choices of $l$. By Equation \ref{Eq:PrimElm} we can write 
 $$M_G(\alpha) = \sum_{j = 1}^n M^{(j)} \theta^j$$ 
 where $M^{j} \in M_{n \times n}(F)$. Since $M_G(\alpha)$ is singular, 
 
 Now $M_G(\alpha) \textbf{u} =0$ yields $M^{(j)}\textbf{u} = 0$ for $j \in \lbrace 1, \ldots , n \rbrace$. Hence
 $$\sum_{j = 1}^n M^{(j)} l_j \textbf{u} = 0$$ for any choice of $l_j$'s in $F$. So $l(M_G(\alpha))$ is not invertible for any choice of $l$.
\end{proof} 
Lemma \ref{Lem:Proj} enables us to test invertibility of a random projection of $l(u_{G,K}) $ i.e. $\sum_{g \in G}
 l(g(\alpha))g \in F[G]$. Although we can avoid writing $M_G(\alpha)$, we still need to compute $l(u_{G,K})$ which
 we call it orbit sum projection problem.


\section{Computing projections of the orbit sum}

By know we have the problem of invertiblity of $M_G(\alpha)$ to $l(\osum{G}{K}) \in K[G]$ for a generic
projection $l$. In this section we present algorithms to compute $\alpha_{G,K}$ in case that $G$ is either abelian or metacyclic. 
We begin by the simplest case which is the cyclic one. Assume $G = \langle g \rangle$ where $\mathrm{Ord}(g) = n$. 

The following lemmas are variants of \cite[Lemma 3 $\&$ Lemma 4]{Kaltofen}, with a slight modification in the proofs.

\begin{lemma}\cite{Kaltofen}\label{modcom}
Assume $K$ is a field, $f\in K[x]$ is of degree $n$ and $s = \lceil\sqrt{n}\rceil$. Given $g_1, \ldots , g_{s}$ and 
$h \in K[x]$ of degree less than $n$, $g_1(h), \ldots g_{s}(h)\,\,\,\mod\,\,\, f$ can be computed in
$O(n^{\frac{3}{4}\omega(\frac{4}{3})})$ where $\omega(\frac{4}{3})$ is the exponent of rectangular matrix 
multiplication as introduced in \cite{LeGall}. 
\end{lemma}

\begin{proof}
Let $t = \lceil n^{3/4} \rceil$ and rewrite $g_1 , \ldots , g_s$ as 
$$g_i = \sum_{j= 0}^{n/t} g_{ij}x^{tj}.$$
Now $g_{ij}$'s are polynomials of degree less than $t$. The next step is to compute $H_i = h^i \mod f$ for $i = 0 , \ldots , t$.
Having $H_i$'s in hand one can form the matrix $H = \left[ H_1 \vert \cdots \vert H_t \right]^T$ where each column is the vector of 
the element $H_i$ (with coefficients in $F$) so the matrix $H$ is of size $t \times n$. We form 
$A = \left[\bar{g}_{10}\vert \cdots \vert \bar{g}_{1(n/t-1)}\vert \cdots \vert \bar{g}_{s0}\vert \cdots \vert \bar{g}_{s(n/t-1)}\right]^T,$
where $\bar{g}_{ij}$ is the  vector of $g_{ij}$. In order to compute $g_{ij}(h)$ one can compute $A \cdot H$. Using 
results from \cite{LeGall}, this can be done in $O(n^{3/4 \omega(4/3)})$. The last step to get $g_i(h)$, is to substitute $H_t$ 
for $x^t$ and performing a Horner evaluation scheme. The dominant term in this calculation is the cost of computing $AH$ which
is $O(n^{3/4 \omega(4/3)})$.
\end{proof}

\begin{lemma}\cite{Kaltofen}
Assume $K$ is a field, $f\in K[x]$ is of degree $n = n_1 \cdots n_r$ and $s_i = \lceil\sqrt{n_i}\rceil$. Given 
$g_1, \ldots , g_{r}$ and $h \in K[x]$ of degree less than $n$, $$g_1^{i_1}\cdots g_r^{i_r}(h) \mod f, 1 \leq j \leq r, 
0 \leq i_j \leq s_i$$ can be 
computed in $\osumcosttilde$ where $\omega(\frac{4}{3})$ is the exponent of rectangular matrix 
multiplication as introduced in \cite{LeGall}. 
\end{lemma}

\begin{proof}
At first assume we have computed $g_1(x), \ldots , g_1^m(x) \mod f$. Then we can compute $g_1^{m+1}(x), \ldots , g_1^{2m}(x)$ by
computing $g_1(g_1^m(x)), \ldots , g_1^m(g_1^m(x)) \mod f$ using Lemma \ref{modcom}. Hence by repeating the doubling method 
$\log s_1$ times, we can compute $g_1(x), \ldots , g_1^{s_1}(x) \mod f$ in $O(\log s_1) \times \osumcost$. Now if we have computed $g_1(h), \ldots , g_1^m(h) \mod f$, we can compute $g_1^{m+1}(h), \ldots , g_1^{2m}(h)$ by computing $g_1(g_1^m(h)), \ldots , g_1^m(g_1^m(h)) \mod f$ using Lemma \ref{modcom}, thus the computation of $g_1(h), \ldots , g_1^{s_1}(h) \mod f$ can be done in $ O(\log s_1) \times \osumcost$ using the above doubling method.

The next step is to apply $g_2^i$ to $g_1(h), \ldots , g_1^{s_1}(h)$ for $0\leq i \leq s_2$. In order to do so we compute 
$$g_2(g_1(h)), \ldots , g_2(g_1^{s_1}(h))$$
using the fact that $g_2(g_1^i(h)) = g_1^i(g_2(h))$ and applying Lemma \ref{modcom} which costs $\osumcost$. At this point we have 
$$\begin{array}{lll} g_1(h)& \ldots & g_1^{s_1}(h)\\ g_2(g_1(h))& \ldots & g_2(g_1^{s_1}(h))\end{array}$$
and by applying $g_2^2$ (using the above method) we get 
$$\begin{array}{lll} g_1(h)& \ldots & g_1^{s_1}(h)\\ g_2(g_1(h))& \ldots & g_2(g_1^{s_1}(h))\\
g_2^2(g_1(h))& \ldots & g_2^2(g_1^{s_1}(h))\\g_2^3(g_1(h))& \ldots & g_2^3(g_1^{s_1}(h))
\end{array}$$
and by doing the same for $g_2^4, \ldots $ we get
$$g_2^{i_2}(g_1^{i_1}(h)), \, 0\leq i_1\leq s_1, 0 \leq i_2 \leq s_2,$$
using $O(\log s_2)\cdot \osumcost + O(\log s_1)\cdot \osumcost$ which is  $O(\log (s_1s_2))\osumcost$. 

Doing the same for $g_3 , \ldots , g_r$ we see the cost of the computation is 
$$O(\log (s_1\cdots s_r))\osumcost = \osumcosttilde.$$

Note that for each $g_i$ we have to compute $g_i^j$ for $0 \leq j \leq s_i$ but this can be carried out with less operations than what 
we have stated for the other computations.
\end{proof}


We do the computations in 3 steps:

\textbf{step 1.} compute $g^i(\alpha)$ for $i = 1, \ldots , \lceil \sqrt{n} \rceil$. Using Lemma 4 this can be done in 
$O(n^{\frac{1}{2}\omega(\frac{4}{3})}).$

\textbf{step 2.} compute $\sqrt{n}$ elements $h_i = \sum_{j = 1}^ {\sqrt{n}-1}a_{ij}g^{j}(\alpha)$ which is actually a rectangular matrix multiplication which uses $O(n^{\frac{1}{2}\omega(\frac{4}{3})}).$ operations in $F$.

\subsection{Abelian Groups}
Assume $G = \langle g_1, \ldots , g_n: g_{1}^{e_1} = \cdots = g_{n}^{e_n} = 1 \rangle$ where $ e_i \in \mathbb{N}$
is the order of $g_i$. Let us re write the sum as 
$$\sum_{\substack{0 \leq i_1 \leq e_1/t_1 \\ \vdots \\ 0 \leq i_n \leq e_n/t_n}} \hat{g}_1^{i_1} \cdots \hat{g}_n^{i_n}(\sum_{\substack{0 \leq j_1 \leq t_1-1\\ \vdots \\ 0 \leq j_n \leq t_n-1}} a^{i_1, \ldots , i_n}_{j_1, \ldots , j_n}g_1^{j_1}\cdots g_n^{j_n}(\alpha))$$
where $t_i = \lceil \sqrt{e_i}\rceil$ and $\hat{g_i} = g_i ^{t_i}.$

It is simpler to think of monomials in $g_i$'s as integral points of $\mathbb{R}^n$ space, i.e.
$(a_1, \ldots , a_n)$ represents $g_1^{a_1}, \ldots g_n^{a_n}$. If this is the case then the above equation suggests to 
partition the $n$-cell $$[0,e_1] \times \cdots \times [0, e_n]$$ into $n$-cells of the same size as 
$$[0,\lceil \sqrt{e_1} \rceil] \times \cdots \times [0, \lceil \sqrt{e_n} \rceil],$$ 
then we can start to compute the automrphism evaluations in the $n$-cell containing the origin. After that each time we apply one 
of the generators we are moving to another $n$-cell.

We compute the projection of the orbit sum of $\alpha$ in 3 steps.

\textbf{step 1. Compute the actions of the points in the $n$-cell containing the origin on $\alpha$}. At first we compute 
$g_1(\alpha), \ldots , g_1^{t_1}(\alpha)$ in $O(\sqrt{\vert G \vert}^{\omega({\frac{3}{4}})})$ operations in $F$, by lemma 4. Now
we apply 

 $g_2$ to $g_1(\alpha), \ldots , g_1^{t_1}(\alpha)$ then after applying $g_2^2$ to
\[
 \begin{array}{lll}
 g_1(\alpha)& \ldots & g_1^{t_1}(\alpha)\\
 g_2(g_1(\alpha))& \ldots & g_2(g_1^{t_1}(\alpha)) 
\end{array} 
\]
we have computed
\[
 \begin{array}{lll}
 g_1(\alpha)& \ldots & g_1^{t_1}(\alpha)\\
 g_2(g_1(\alpha))& \ldots & g_2(g_1^{t_1}(\alpha)) \\
 g_2^2(g_1(\alpha))& \ldots & g_2^2(g_1^{t_1}(\alpha)) \\
 g_2^3(g_1(\alpha))& \ldots & g_2^3(g_1^{t_1}(\alpha))
\end{array} 
\]
If we continue by applying $g_2^4, \ldots$ we are able to get
\[
 \begin{array}{lll}
 g_1(\alpha)& \ldots & g_1^{t_1}(\alpha)\\
 g_2(g_1(\alpha))& \ldots & g_2(g_1^{t_1}(\alpha)) \\
 \vdots & \vdots & \vdots\\
 g_2^{t_2}(g_1(\alpha))& \ldots & g_2^{t_2}(g_1^{t_1}(\alpha)) \\
\end{array} 
\]
Note that computing 
$$g_2^{j}(g_1(\alpha)), \ldots , g_2^{j}(g_1^{t_1}(\alpha))$$
is equivalent of computing 
$$g_1(g_2^{j}(\alpha)), \ldots , g_1^{t_1}(g_2^{j}(\alpha)).$$
This shows that above computation can be done in $(\log \sqrt{t_2})(\vert G \vert ^{\frac{1}{2}\omega(\frac{4}{3})})$ operations in $F$. By doing similar operations for $g_3, \ldots, g_n$ on all the outputs we can compute the corresponding images to the elements
of the $n$-cell containing the origin in $\tilde{O}(\vert G \vert ^{\frac{1}{2}\omega(\frac{4}{3})})$

\textbf{step2. computing automorphism evaluations in the $n$-cell containing the origin.}

We want to compute
$$T_{i_1, \ldots, i_n} = \sum_{\substack{0 \leq j_1 \leq t_1\\ \vdots \\ 0 \leq j_n \leq t_n}} a^{i_1, \ldots , i_n}_{j_1, \ldots , j_n}g_1^{j_1}\cdots g_n^{j_n}(\alpha)$$
for $0 \leq i_1-1 \leq t_1, \ldots , 0 \leq i_n \leq t_n-1$ which can be carried out by a $\langle \sqrt{\vert G \vert}, \langle \sqrt{\vert G \vert}, \vert G \vert$ rectangular matrix multiplication which can be done by 
$\vert G \vert ^{\frac{1}{2}\omega(\frac{4}{3})}$.

\textbf{step 3. applying $\hat{g}_i$'s.}

We have already computed $\hat{g}_i$ in step 1. Similar to step 1, we can apply $g_i^s$ 
for $s = 1, 2, 4 , \ldots, t_1$ to $T_{i_1, \ldots , i_n}$ which can be done using $(\log t_i)(\vert G \vert^{\frac{1}{2}\omega
(\frac{4}{3})})$ operations in $F$. Thus this step can be carried out by $\tilde{O}(\vert G \vert^{\frac{1}{2}\omega
(\frac{4}{3})})$ operations in $F$.

\subsection{Metacyclic Groups}

It is known that a metacyclic group can be presented as $\langle a,b: a^m = 1, b^{-1}ab = b^r, b^n = x^s \rangle$
where $m,n,r,s \in \mathbb{N}, r,s \leq m,$ and $r^n = 1 \mod m , rs = s \mod m$. Moreover we know that all element of a metacyclic group can be presented by 
$$a^ib^j, \,\,\, 0\leq i \leq m-1, 0\leq j \leq n-1$$ 
See \cite[P.88, Proposition 1]{Johnson}, \cite[P.334]{Curtis} for more details.


\section{Testing Invertiblity of an Element of the Group Algebra}



\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography} 

\end{document}
